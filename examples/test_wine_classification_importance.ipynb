{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000da05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Wine Classification - Overall and Local Feature Importance\n",
    "Tests all 4 configurations: GPU/CPU × Casewise/Non-casewise\n",
    "Includes: OOB Error, Confusion Matrix, Overall Importance, Local Importance\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import rfx as rf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f003d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature names for Wine dataset\n",
    "FEATURE_NAMES = [\n",
    "    'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash',\n",
    "    'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols',\n",
    "    'Proanthocyanins', 'Color intensity', 'Hue',\n",
    "    'OD280/OD315 of diluted wines', 'Proline'\n",
    "]\n",
    "\n",
    "CLASS_NAMES = ['Class 0', 'Class 1', 'Class 2']\n",
    "\n",
    "def print_confusion_matrix(cm, n_classes):\n",
    "    \"\"\"Pretty print confusion matrix\"\"\"\n",
    "    # Header\n",
    "    header = \"          \" + \"  \".join(f\"Pred {i}\" for i in range(n_classes))\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    \n",
    "    # Rows\n",
    "    for i in range(n_classes):\n",
    "        row = f\"True {i}  |\"\n",
    "        for j in range(n_classes):\n",
    "            row += f\"   {cm[i, j]:3d}  \"\n",
    "        print(row)\n",
    "    print()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2379a606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: Wine (UCI ML - built-in)\n",
      "   Samples: 178\n",
      "   Features: 13\n",
      "   Classes: 3\n",
      "   Class distribution: [59, 71, 48]\n"
     ]
    }
   ],
   "source": [
    "# Load Wine dataset (built-in)\n",
    "X, y = rf.load_wine()\n",
    "n_samples, n_features = X.shape\n",
    "n_classes = len(np.unique(y))\n",
    "\n",
    "print(f\"\\nDataset: Wine (UCI ML - built-in)\")\n",
    "print(f\"   Samples: {n_samples}\")\n",
    "print(f\"   Features: {n_features}\")\n",
    "print(f\"   Classes: {n_classes}\")\n",
    "print(f\"   Class distribution: {np.bincount(y).tolist()}\")\n",
    "\n",
    "# Run all 4 configurations\n",
    "ntree = 100\n",
    "results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57deca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. GPU casewise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e84335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU casewise\n",
    "use_gpu = True\n",
    "mode='gpu' if use_gpu else 'cpu'\n",
    "use_casewise=True\n",
    "weighting = 'case-wise' if use_casewise else 'non-case-wise'\n",
    "run_type='gpu_cw'\n",
    "# Create model with overall AND local importance\n",
    "model = rf.RandomForestClassifier(\n",
    "    ntree=ntree,\n",
    "    mtry=4,  # sqrt(13) ≈ 3.6\n",
    "    nsample=X.shape[0],\n",
    "    nclass=n_classes,\n",
    "    use_gpu=use_gpu,\n",
    "    batch_size=25,\n",
    "    iseed=42,\n",
    "    compute_proximity=False,\n",
    "    compute_importance=True,          # Overall importance\n",
    "    compute_local_importance=True,    # Local importance (per-sample)\n",
    "    use_casewise=use_casewise\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  {mode.upper()} {weighting.upper()}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nTraining {ntree} trees...\")\n",
    "start_time = time.time()\n",
    "model.fit(X, y)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "# Get results\n",
    "oob_error = model.get_oob_error()\n",
    "oob_preds = model.get_oob_predictions()\n",
    "overall_imp = model.feature_importances_()\n",
    "local_imp = model.get_local_importance()\n",
    "\n",
    "print(f\"Training time: {elapsed:.2f}s ({ntree/elapsed:.1f} trees/sec)\")\n",
    "\n",
    "# OOB Error\n",
    "print(f\"\\nOOB Error: {oob_error:.6f} ({oob_error*100:.2f}%)\")\n",
    "print(f\"   OOB Accuracy: {(1-oob_error)*100:.2f}%\")\n",
    "\n",
    "# Overall Feature Importance\n",
    "print(f\"\\nOverall Feature Importance (Top 5):\")\n",
    "sorted_idx = np.argsort(overall_imp)[::-1]\n",
    "for rank, idx in enumerate(sorted_idx[:5], 1):\n",
    "    print(f\"   {rank}. {FEATURE_NAMES[idx]:<35} {overall_imp[idx]:.6f}\")\n",
    "\n",
    "# Local Importance Statistics\n",
    "print(f\"\\nLocal Importance: shape={local_imp.shape}\")\n",
    "local_mean = np.mean(local_imp, axis=0)\n",
    "sorted_local_idx = np.argsort(local_mean)[::-1]\n",
    "print(f\"   Top 3 by mean: {', '.join([FEATURE_NAMES[i] for i in sorted_local_idx[:3]])}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = rf.confusion_matrix(y.astype(np.int32), oob_preds.astype(np.int32))\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print_confusion_matrix(cm, n_classes)\n",
    "\n",
    "# Classification Report\n",
    "print(f\"Classification Report:\")\n",
    "print(rf.classification_report(y.astype(np.int32), oob_preds.astype(np.int32)))\n",
    "\n",
    "results[run_type] = {\n",
    "    'mode': f\"{mode} {weighting}\",\n",
    "    'oob_error': oob_error,\n",
    "    'confusion_matrix': cm,\n",
    "    'time': elapsed,\n",
    "    'oob_preds': oob_preds,\n",
    "    'overall_imp': overall_imp,\n",
    "    'local_imp': local_imp\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba95de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU noncasewise\n",
    "use_gpu = True\n",
    "mode='gpu' if use_gpu else 'cpu'\n",
    "use_casewise=False\n",
    "weighting = 'case-wise' if use_casewise else 'non-case-wise'\n",
    "run_type='gpu_ncw'\n",
    "# Create model with overall AND local importance\n",
    "model = rf.RandomForestClassifier(\n",
    "    ntree=ntree,\n",
    "    mtry=4,  # sqrt(13) ≈ 3.6\n",
    "    nsample=X.shape[0],\n",
    "    nclass=n_classes,\n",
    "    use_gpu=use_gpu,\n",
    "    batch_size=25,\n",
    "    iseed=42,\n",
    "    compute_proximity=False,\n",
    "    compute_importance=True,          # Overall importance\n",
    "    compute_local_importance=True,    # Local importance (per-sample)\n",
    "    use_casewise=use_casewise\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  {mode.upper()} {weighting.upper()}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nTraining {ntree} trees...\")\n",
    "start_time = time.time()\n",
    "model.fit(X, y)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "# Get results\n",
    "oob_error = model.get_oob_error()\n",
    "oob_preds = model.get_oob_predictions()\n",
    "overall_imp = model.feature_importances_()\n",
    "local_imp = model.get_local_importance()\n",
    "\n",
    "print(f\"Training time: {elapsed:.2f}s ({ntree/elapsed:.1f} trees/sec)\")\n",
    "\n",
    "# OOB Error\n",
    "print(f\"\\nOOB Error: {oob_error:.6f} ({oob_error*100:.2f}%)\")\n",
    "print(f\"   OOB Accuracy: {(1-oob_error)*100:.2f}%\")\n",
    "\n",
    "# Overall Feature Importance\n",
    "print(f\"\\nOverall Feature Importance (Top 5):\")\n",
    "sorted_idx = np.argsort(overall_imp)[::-1]\n",
    "for rank, idx in enumerate(sorted_idx[:5], 1):\n",
    "    print(f\"   {rank}. {FEATURE_NAMES[idx]:<35} {overall_imp[idx]:.6f}\")\n",
    "\n",
    "# Local Importance Statistics\n",
    "print(f\"\\nLocal Importance: shape={local_imp.shape}\")\n",
    "local_mean = np.mean(local_imp, axis=0)\n",
    "sorted_local_idx = np.argsort(local_mean)[::-1]\n",
    "print(f\"   Top 3 by mean: {', '.join([FEATURE_NAMES[i] for i in sorted_local_idx[:3]])}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = rf.confusion_matrix(y.astype(np.int32), oob_preds.astype(np.int32))\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print_confusion_matrix(cm, n_classes)\n",
    "\n",
    "# Classification Report\n",
    "print(f\"Classification Report:\")\n",
    "print(rf.classification_report(y.astype(np.int32), oob_preds.astype(np.int32)))\n",
    "\n",
    "results[run_type] = {\n",
    "    'mode': f\"{mode} {weighting}\",\n",
    "    'oob_error': oob_error,\n",
    "    'confusion_matrix': cm,\n",
    "    'time': elapsed,\n",
    "    'oob_preds': oob_preds,\n",
    "    'overall_imp': overall_imp,\n",
    "    'local_imp': local_imp\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef0b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPU noncasewise\n",
    "use_gpu = False\n",
    "mode='gpu' if use_gpu else 'cpu'\n",
    "use_casewise=False\n",
    "weighting = 'case-wise' if use_casewise else 'non-case-wise'\n",
    "run_type='cpu_ncw'\n",
    "# Create model with overall AND local importance\n",
    "model = rf.RandomForestClassifier(\n",
    "    ntree=ntree,\n",
    "    mtry=4,  # sqrt(13) ≈ 3.6\n",
    "    nsample=X.shape[0],\n",
    "    nclass=n_classes,\n",
    "    use_gpu=use_gpu,\n",
    "    batch_size=25,\n",
    "    iseed=42,\n",
    "    compute_proximity=False,\n",
    "    compute_importance=True,          # Overall importance\n",
    "    compute_local_importance=True,    # Local importance (per-sample)\n",
    "    use_casewise=use_casewise\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  {mode.upper()} {weighting.upper()}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nTraining {ntree} trees...\")\n",
    "start_time = time.time()\n",
    "model.fit(X, y)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "# Get results\n",
    "oob_error = model.get_oob_error()\n",
    "oob_preds = model.get_oob_predictions()\n",
    "overall_imp = model.feature_importances_()\n",
    "local_imp = model.get_local_importance()\n",
    "\n",
    "print(f\"Training time: {elapsed:.2f}s ({ntree/elapsed:.1f} trees/sec)\")\n",
    "\n",
    "# OOB Error\n",
    "print(f\"\\nOOB Error: {oob_error:.6f} ({oob_error*100:.2f}%)\")\n",
    "print(f\"   OOB Accuracy: {(1-oob_error)*100:.2f}%\")\n",
    "\n",
    "# Overall Feature Importance\n",
    "print(f\"\\nOverall Feature Importance (Top 5):\")\n",
    "sorted_idx = np.argsort(overall_imp)[::-1]\n",
    "for rank, idx in enumerate(sorted_idx[:5], 1):\n",
    "    print(f\"   {rank}. {FEATURE_NAMES[idx]:<35} {overall_imp[idx]:.6f}\")\n",
    "\n",
    "# Local Importance Statistics\n",
    "print(f\"\\nLocal Importance: shape={local_imp.shape}\")\n",
    "local_mean = np.mean(local_imp, axis=0)\n",
    "sorted_local_idx = np.argsort(local_mean)[::-1]\n",
    "print(f\"   Top 3 by mean: {', '.join([FEATURE_NAMES[i] for i in sorted_local_idx[:3]])}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = rf.confusion_matrix(y.astype(np.int32), oob_preds.astype(np.int32))\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print_confusion_matrix(cm, n_classes)\n",
    "\n",
    "# Classification Report\n",
    "print(f\"Classification Report:\")\n",
    "print(rf.classification_report(y.astype(np.int32), oob_preds.astype(np.int32)))\n",
    "\n",
    "results[run_type] = {\n",
    "    'mode': f\"{mode} {weighting}\",\n",
    "    'oob_error': oob_error,\n",
    "    'confusion_matrix': cm,\n",
    "    'time': elapsed,\n",
    "    'oob_preds': oob_preds,\n",
    "    'overall_imp': overall_imp,\n",
    "    'local_imp': local_imp\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPU casewise\n",
    "use_gpu = False\n",
    "mode='gpu' if use_gpu else 'cpu'\n",
    "use_casewise=True\n",
    "weighting = 'case-wise' if use_casewise else 'non-case-wise'\n",
    "run_type='cpu_cw'\n",
    "# Create model with overall AND local importance\n",
    "model = rf.RandomForestClassifier(\n",
    "    ntree=ntree,\n",
    "    mtry=4,  # sqrt(13) ≈ 3.6\n",
    "    nsample=X.shape[0],\n",
    "    nclass=n_classes,\n",
    "    use_gpu=use_gpu,\n",
    "    batch_size=25,\n",
    "    iseed=42,\n",
    "    compute_proximity=False,\n",
    "    compute_importance=True,          # Overall importance\n",
    "    compute_local_importance=True,    # Local importance (per-sample)\n",
    "    use_casewise=use_casewise\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  {mode.upper()} {weighting.upper()}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nTraining {ntree} trees...\")\n",
    "start_time = time.time()\n",
    "model.fit(X, y)\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "# Get results\n",
    "oob_error = model.get_oob_error()\n",
    "oob_preds = model.get_oob_predictions()\n",
    "overall_imp = model.feature_importances_()\n",
    "local_imp = model.get_local_importance()\n",
    "\n",
    "print(f\"Training time: {elapsed:.2f}s ({ntree/elapsed:.1f} trees/sec)\")\n",
    "\n",
    "# OOB Error\n",
    "print(f\"\\nOOB Error: {oob_error:.6f} ({oob_error*100:.2f}%)\")\n",
    "print(f\"   OOB Accuracy: {(1-oob_error)*100:.2f}%\")\n",
    "\n",
    "# Overall Feature Importance\n",
    "print(f\"\\nOverall Feature Importance (Top 5):\")\n",
    "sorted_idx = np.argsort(overall_imp)[::-1]\n",
    "for rank, idx in enumerate(sorted_idx[:5], 1):\n",
    "    print(f\"   {rank}. {FEATURE_NAMES[idx]:<35} {overall_imp[idx]:.6f}\")\n",
    "\n",
    "# Local Importance Statistics\n",
    "print(f\"\\nLocal Importance: shape={local_imp.shape}\")\n",
    "local_mean = np.mean(local_imp, axis=0)\n",
    "sorted_local_idx = np.argsort(local_mean)[::-1]\n",
    "print(f\"   Top 3 by mean: {', '.join([FEATURE_NAMES[i] for i in sorted_local_idx[:3]])}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = rf.confusion_matrix(y.astype(np.int32), oob_preds.astype(np.int32))\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "print_confusion_matrix(cm, n_classes)\n",
    "\n",
    "# Classification Report\n",
    "print(f\"Classification Report:\")\n",
    "print(rf.classification_report(y.astype(np.int32), oob_preds.astype(np.int32)))\n",
    "\n",
    "results[run_type] = {\n",
    "    'mode': f\"{mode} {weighting}\",\n",
    "    'oob_error': oob_error,\n",
    "    'confusion_matrix': cm,\n",
    "    'time': elapsed,\n",
    "    'oob_preds': oob_preds,\n",
    "    'overall_imp': overall_imp,\n",
    "    'local_imp': local_imp\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e9f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"  WINE CLASSIFICATION - OVERALL & LOCAL IMPORTANCE\")\n",
    "print(\"  Testing: GPU/CPU × Casewise/Non-casewise\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"  SUMMARY COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nOOB Errors:\")\n",
    "print(f\"   {'Configuration':<25s} {'OOB Error':>12s} {'Accuracy':>12s} {'Time':>10s}\")\n",
    "print(\"   \" + \"-\" * 60)\n",
    "for key, res in results.items():\n",
    "    print(f\"   {res['mode']:<25s} {res['oob_error']:>12.6f} {(1-res['oob_error'])*100:>11.2f}% {res['time']:>9.2f}s\")\n",
    "\n",
    "# Feature Importance Comparison\n",
    "print(\"\\nTop 3 Features by Overall Importance:\")\n",
    "print(f\"   {'Configuration':<25s} {'#1':<20s} {'#2':<20s} {'#3':<20s}\")\n",
    "print(f\"   {'-'*85}\")\n",
    "for key, res in results.items():\n",
    "    sorted_idx = np.argsort(res['overall_imp'])[::-1]\n",
    "    top3 = [FEATURE_NAMES[i][:18] for i in sorted_idx[:3]]\n",
    "    print(f\"   {res['mode']:<25s} {top3[0]:<20s} {top3[1]:<20s} {top3[2]:<20s}\")\n",
    "\n",
    "# Importance Correlation\n",
    "try:\n",
    "    from scipy.stats import spearmanr\n",
    "    print(\"\\nOverall Importance Spearman Correlations:\")\n",
    "    configs = list(results.keys())\n",
    "    print(f\"   {'':25s}\", end=\"\")\n",
    "    for c in configs:\n",
    "        print(f\"{results[c]['mode'][:12]:>14s}\", end=\"\")\n",
    "    print()\n",
    "    for c1 in configs:\n",
    "        print(f\"   {results[c1]['mode']:<25s}\", end=\"\")\n",
    "        for c2 in configs:\n",
    "            corr, _ = spearmanr(results[c1]['overall_imp'], results[c2]['overall_imp'])\n",
    "            print(f\"{corr:>14.4f}\", end=\"\")\n",
    "        print()\n",
    "except ImportError:\n",
    "    print(\"\\n   (scipy not available for correlation analysis)\")\n",
    "\n",
    "print(\"\\nCasewise vs Non-casewise Differences:\")\n",
    "gpu_diff = abs(results['gpu_cw']['oob_error'] - results['gpu_ncw']['oob_error'])\n",
    "cpu_diff = abs(results['cpu_cw']['oob_error'] - results['cpu_ncw']['oob_error'])\n",
    "print(f\"   GPU:  {gpu_diff:.6f} ({gpu_diff*100:.2f}% difference)\")\n",
    "print(f\"   CPU:  {cpu_diff:.6f} ({cpu_diff*100:.2f}% difference)\")\n",
    "\n",
    "if gpu_diff < 0.001 and cpu_diff < 0.001:\n",
    "    print(\"\\n   WARNING: Casewise and non-casewise produce IDENTICAL results!\")\n",
    "else:\n",
    "    print(\"\\n   Casewise and non-casewise produce DIFFERENT results (expected!)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"  TEST COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcec6a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
